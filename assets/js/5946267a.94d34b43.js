"use strict";(self.webpackChunkwebsite=self.webpackChunkwebsite||[]).push([[575],{3987:(e,n,s)=>{s.r(n),s.d(n,{assets:()=>o,contentTitle:()=>r,default:()=>h,frontMatter:()=>i,metadata:()=>a,toc:()=>c});var t=s(4848),l=s(8453);const i={sidebar_position:2},r="New Types for the library",a={id:"Contributing/CreateNewType",title:"New Types for the library",description:"This is a guide on how to add a new type to the library",source:"@site/../docs/Contributing/CreateNewType.md",sourceDirName:"Contributing",slug:"/Contributing/CreateNewType",permalink:"/big-data-types/docs/Contributing/CreateNewType",draft:!1,unlisted:!1,editUrl:"https://github.com/data-tools/big-data-types/edit/main/website/../docs/Contributing/CreateNewType.md",tags:[],version:"current",sidebarPosition:2,frontMatter:{sidebar_position:2},sidebar:"tutorialSidebar",previous:{title:"Contributions",permalink:"/big-data-types/docs/Contributing/Contributions"}},o={},c=[{value:"How to develop a new type",id:"how-to-develop-a-new-type",level:2},{value:"How it works",id:"how-it-works",level:2},{value:"SqlType ADT",id:"sqltype-adt",level:2},{value:"Conversion / Reverse Conversion",id:"conversion--reverse-conversion",level:2},{value:"Conversion",id:"conversion",level:3},{value:"Reverse Conversion",id:"reverse-conversion",level:3},{value:"How to do it",id:"how-to-do-it",level:2},{value:"Create a new subproject in SBT",id:"create-a-new-subproject-in-sbt",level:2},{value:"Preparing Tests",id:"preparing-tests",level:2},{value:"Tests for reverse conversion",id:"tests-for-reverse-conversion",level:3},{value:"Conversion: Type Class - SqlType to New Type",id:"conversion-type-class---sqltype-to-new-type",level:2},{value:"Defining the syntax",id:"defining-the-syntax",level:3},{value:"Implementing the Type Class",id:"implementing-the-type-class",level:3},{value:"Mode inside Types",id:"mode-inside-types",level:4},{value:"Everything together",id:"everything-together",level:3},{value:"Conversion: SqlInstance to New Type",id:"conversion-sqlinstance-to-new-type",level:2},{value:"Reverse conversion: New Type to SqlType",id:"reverse-conversion-new-type-to-sqltype",level:2},{value:"Everything together",id:"everything-together-1",level:2}];function d(e){const n={a:"a",admonition:"admonition",code:"code",div:"div",em:"em",h1:"h1",h2:"h2",h3:"h3",h4:"h4",li:"li",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,l.R)(),...e.components};return(0,t.jsxs)(t.Fragment,{children:[(0,t.jsx)(n.h1,{id:"new-types-for-the-library",children:"New Types for the library"}),"\n",(0,t.jsx)(n.p,{children:"This is a guide on how to add a new type to the library"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsx)(n.li,{children:(0,t.jsx)(n.a,{href:"#how-to-develop-a-new-type",children:"How to develop a new type"})}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.a,{href:"#how-it-works",children:"How it works"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsx)(n.li,{children:(0,t.jsx)(n.a,{href:"#sqltype-adt",children:"SqlType ADT"})}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.a,{href:"#conversion--reverse-conversion",children:"Conversion / Reverse Conversion"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsx)(n.li,{children:(0,t.jsx)(n.a,{href:"#conversion",children:"Conversion"})}),"\n",(0,t.jsx)(n.li,{children:(0,t.jsx)(n.a,{href:"#reverse-conversion",children:"Reverse Conversion"})}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.a,{href:"#how-to-do-it",children:"How to do it"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsx)(n.li,{children:(0,t.jsx)(n.a,{href:"#create-a-new-subproject-in-sbt",children:"Create a new subproject in SBT"})}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.a,{href:"#conversion-type-class---sqltype-to-new-type",children:"Conversion: Type Class - SqlType to New Type"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsx)(n.li,{children:(0,t.jsx)(n.a,{href:"#defining-the-syntax",children:"Defining the syntax"})}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.a,{href:"#implementing-the-type-class",children:"Implementing the Type Class"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsx)(n.li,{children:(0,t.jsx)(n.a,{href:"#mode-inside-types",children:"Mode inside Types"})}),"\n"]}),"\n"]}),"\n",(0,t.jsx)(n.li,{children:(0,t.jsx)(n.a,{href:"#everything-together",children:"Everything together"})}),"\n"]}),"\n"]}),"\n",(0,t.jsx)(n.li,{children:(0,t.jsx)(n.a,{href:"#conversion-sqlinstance-to-new-type",children:"Conversion: SqlInstance to New Type"})}),"\n",(0,t.jsx)(n.li,{children:(0,t.jsx)(n.a,{href:"#reverse-conversion-new-type-to-sqltype",children:"Reverse conversion: New Type to SqlType"})}),"\n",(0,t.jsx)(n.li,{children:(0,t.jsx)(n.a,{href:"#everything-together",children:"Everything together"})}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,t.jsx)(n.h2,{id:"how-to-develop-a-new-type",children:"How to develop a new type"}),"\n",(0,t.jsx)(n.p,{children:"Adding a new type to the library will allow conversions from any developed type into the new one\nand from the new one into any of the others"}),"\n",(0,t.jsx)(n.h2,{id:"how-it-works",children:"How it works"}),"\n",(0,t.jsxs)(n.p,{children:["There is an ADT (sealed trait) called ",(0,t.jsx)(n.code,{children:"SqlType"})," that is used as a generic type for any transformation.\nIt works as a bridge, so any developed type can be transformed into SqlType and SqlType can be converted into specific types."]}),"\n",(0,t.jsxs)(n.p,{children:["By doing so, when we add a new type, we don't need to implement conversions between all the types, we only need to implement\n",(0,t.jsx)(n.code,{children:"Conversion"})," from our type to ",(0,t.jsx)(n.code,{children:"SqlType"})," and ",(0,t.jsx)(n.code,{children:"Reverse Conversion"})," from ",(0,t.jsx)(n.code,{children:"SqlType"})," to our type,\nand ",(0,t.jsx)(n.strong,{children:"we will get automatically conversion from / to the rest of the types in the library"}),"."]}),"\n",(0,t.jsx)(n.p,{children:"An important note of nomenclature:"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:["We call ",(0,t.jsx)(n.code,{children:"Conversion"})," to anything that converts ",(0,t.jsx)(n.code,{children:"into the geneic SqlType"})]}),"\n",(0,t.jsxs)(n.li,{children:["We call ",(0,t.jsx)(n.code,{children:"Reverse Conversion"})," to anything that converts ",(0,t.jsx)(n.code,{children:"from generic SqlType into specific"})]}),"\n"]}),"\n",(0,t.jsx)(n.h2,{id:"sqltype-adt",children:"SqlType ADT"}),"\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.a,{href:"https://github.com/data-tools/big-data-types/blob/main/core/src/main/scala/org/datatools/bigdatatypes/types/basic/SqlType.scala",children:"SqlType"}),"\nis an Algebraic Data Type that aims to generalize all the cases that we can have from different types."]}),"\n",(0,t.jsx)(n.p,{children:"It is used internally for all the conversions."}),"\n",(0,t.jsxs)(n.p,{children:["It consists in a few case class with a ",(0,t.jsx)(n.code,{children:"Mode"})," (Nullable, Required or Repeated) and one SqlStruct that contains a\nmap of ",(0,t.jsx)(n.code,{children:"String"})," and ",(0,t.jsx)(n.code,{children:"SqlType"}),', being the String the name of the "field"']}),"\n",(0,t.jsx)(n.h2,{id:"conversion--reverse-conversion",children:"Conversion / Reverse Conversion"}),"\n",(0,t.jsx)(n.p,{children:"There are 2 type of conversions that we should cover"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.code,{children:"Conversion"})," = Generic SqlType -> Our Type"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.code,{children:"Reverse Conversion"})," = Our type -> Generic SqlType"]}),"\n"]}),"\n",(0,t.jsx)(n.h3,{id:"conversion",children:"Conversion"}),"\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.code,{children:"SqlType -> our type"})," = ",(0,t.jsx)(n.code,{children:"All types -> our type"}),"\nFor the ",(0,t.jsx)(n.em,{children:"normal"})," ",(0,t.jsx)(n.em,{children:"Conversion"})," we have to create two new ",(0,t.jsx)(n.em,{children:"Type Classes"}),"\nThe ",(0,t.jsx)(n.strong,{children:"Core"})," of the library already have a ",(0,t.jsx)(n.em,{children:"Type Class"})," that converts Case Classes into ",(0,t.jsx)(n.code,{children:"SqlTypes"})," so our new ",(0,t.jsx)(n.em,{children:"Type Classes"})," only need to derive from there."]}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.code,{children:"SqlTypeToOurType"})," for only types (converting a Case Class into our new type) -> e.g: ",(0,t.jsx)(n.code,{children:"Conversion[A].myNewType"})]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.code,{children:"SqlInstanceToOurType"})," for convert instances into our new type -> e.g: ",(0,t.jsx)(n.code,{children:"Conversion[A](myInstance: A).myNewType"}),"\n(",(0,t.jsx)(n.code,{children:"A"})," could be an instance of any implemented type in the library)"]}),"\n"]}),"\n",(0,t.jsx)(n.p,{children:"One will be based on the other one, so don't worry, one will be really short."}),"\n",(0,t.jsx)(n.h3,{id:"reverse-conversion",children:"Reverse Conversion"}),"\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.code,{children:"our type -> SqlType"})," = ",(0,t.jsx)(n.code,{children:"our type -> all types"})]}),"\n",(0,t.jsxs)(n.p,{children:["In order to implement the conversion from our new type to ",(0,t.jsx)(n.code,{children:"SqlType"})," we have to implement\nan existing ",(0,t.jsx)(n.em,{children:"Type Class"})," called ",(0,t.jsx)(n.code,{children:"SqlTypeConversion"})]}),"\n",(0,t.jsx)(n.p,{children:"By doing this, we will get automatically conversion to the rest of the types of the library"}),"\n",(0,t.jsx)(n.h2,{id:"how-to-do-it",children:"How to do it"}),"\n",(0,t.jsxs)(n.p,{children:["As covered in ",(0,t.jsx)(n.a,{href:"#conversion",children:"Conversion"}),", we have to implement 2 types classes, one for types, another for instances.\nBoth will derive ",(0,t.jsx)(n.code,{children:"SqlTypeConversion"})," type class into our specific type and by doing so, we will get automatically all conversions into our new type"]}),"\n",(0,t.jsx)(n.h2,{id:"create-a-new-subproject-in-sbt",children:"Create a new subproject in SBT"}),"\n",(0,t.jsx)(n.p,{children:"For a new type, we need a new submodule in SBT, by doing so, we don't force anyone to import all implemented types in the library, so anyone can pick only the types that is interested in"}),"\n",(0,t.jsxs)(n.p,{children:["An example from Spark. This defines a new module ",(0,t.jsx)(n.code,{children:"big-data-types-spark"}),".\nOptions can be changed as desired:"]}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsx)(n.li,{children:"publishSettings seems to be obvious as we want to publish the new type"}),"\n",(0,t.jsx)(n.li,{children:"crossScalaVersions specify the different Scala versions that the artifact will be created. The more the better"}),"\n",(0,t.jsx)(n.li,{children:"crossVersionSharedSources is a method to specify different code for Scala 2.13- or 2.13+"}),"\n",(0,t.jsx)(n.li,{children:"Dependencies, defined in a variable, the ones that we need"}),"\n",(0,t.jsx)(n.li,{children:"dependsOn for depend on Core for compile and for tests. (There are a few useful classes in Core/Tests that we can use to test our new type)"}),"\n"]}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-scala",children:'lazy val spark = (project in file("spark"))\n  .settings(\n    name := projectName + "-spark",\n    publishSettings,\n    crossScalaVersions := List(scala212),\n    crossVersionSharedSources,\n    libraryDependencies ++= sparkDependencies\n  )\n  .dependsOn(core % "test->test;compile->compile")\n'})}),"\n",(0,t.jsxs)(n.p,{children:["Add the dependency to the root project, inside ",(0,t.jsx)(n.code,{children:"aggregate"}),":"]}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-scala",children:'//Project settings\nlazy val root = (project in file("."))\n  .configs(IntegrationTest)\n  .settings(noPublishSettings)\n  .aggregate(\n    core,\n    bigquery,\n    spark,\n    examples\n  )\n'})}),"\n",(0,t.jsx)(n.p,{children:"Now, you can create a new root folder with your type name with the typical structure (src/main/scala_ ...)"}),"\n",(0,t.jsx)(n.h2,{id:"preparing-tests",children:"Preparing Tests"}),"\n",(0,t.jsx)(n.div,{children:(0,t.jsx)(n.p,{children:"You can develop the conversion before tests, but we recommend to create a set of test before starting to develop a new type,\nit helps a lot to understand your new type and how it is being created.\nSometimes a type is not as easy as it seems."})}),"\n",(0,t.jsxs)(n.p,{children:["In the ",(0,t.jsx)(n.code,{children:"core"})," module of the library there are some case classes that should cover all the different scenarios\n(different types, lists, objects, deep nested objects) so the testing part will consist on:"]}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsx)(n.li,{children:"1 - Create instances of your new types"}),"\n",(0,t.jsxs)(n.li,{children:["2 - Pick the already defined ",(0,t.jsx)(n.a,{target:"_blank",href:s(805).A+"",children:"Test Case Classes"})]}),"\n",(0,t.jsx)(n.li,{children:"Test that 1 can be converted into 2"}),"\n",(0,t.jsx)(n.li,{children:"Test that 2 can be converted into 1"}),"\n"]}),"\n",(0,t.jsxs)(n.admonition,{type:"tip",children:[(0,t.jsx)(n.p,{children:"You will need to understand the following about your new type:"}),(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsx)(n.li,{children:"How types are being created"}),"\n",(0,t.jsx)(n.li,{children:"How nullable fields works (with Optional types, nullable parameters ...)"}),"\n",(0,t.jsx)(n.li,{children:"How lists and nested objects works (if they exist)"}),"\n"]})]}),"\n",(0,t.jsxs)(n.p,{children:["To do so, first, create a new ",(0,t.jsx)(n.code,{children:"test/scala"})," folder with ",(0,t.jsx)(n.code,{children:"org.datatools.bigdatatypes"})," and create an object like ",(0,t.jsx)(n.code,{children:"MyTypeTestTypes"})]}),"\n",(0,t.jsx)(n.p,{children:"See the example of Spark Types:"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-scala",children:'object SparkTestTypes {\n\n  val basicFields: Seq[StructField] =\n    List(\n      StructField("myInt", IntegerType, nullable = false),\n      StructField("myLong", LongType, nullable = false),\n      StructField("myFloat", FloatType, nullable = false),\n      StructField("myDouble", DoubleType, nullable = false),\n      StructField("myDecimal", DataTypes.createDecimalType, nullable = false),\n      StructField("myBoolean", BooleanType, nullable = false),\n      StructField("myString", StringType, nullable = false)\n    )\n  val basicWithList: Seq[StructField] =\n    List(\n      StructField("myInt", IntegerType, nullable = false),\n      StructField("myList", ArrayType(IntegerType), nullable = true)\n    )\n// ...\n}\n'})}),"\n",(0,t.jsxs)(n.p,{children:["Create a new package for your tests called ",(0,t.jsx)(n.code,{children:"myType"})," and add there a new class for each conversion."]}),"\n",(0,t.jsx)(n.h3,{id:"tests-for-reverse-conversion",children:"Tests for reverse conversion"}),"\n",(0,t.jsx)(n.p,{children:"From our type to the generic one"}),"\n",(0,t.jsxs)(n.p,{children:["Create a file called ",(0,t.jsx)(n.code,{children:"MyTypeConversionSpec"})," and add there some tests. You can add the following tests:"]}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsx)(n.li,{children:"Simple individual type"}),"\n",(0,t.jsx)(n.li,{children:"Product type (case class / object)"}),"\n",(0,t.jsx)(n.li,{children:"Lists"}),"\n",(0,t.jsx)(n.li,{children:"Nested objects"}),"\n",(0,t.jsxs)(n.li,{children:["Some extra tests for extension methods (syntactic sugars like ",(0,t.jsx)(n.code,{children:".asSqlType"})," or ",(0,t.jsx)(n.code,{children:".asBigQuery"})," in normal conversion)"]}),"\n"]}),"\n",(0,t.jsx)(n.p,{children:"e.g. from Spark:"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-scala",children:'class SparkTypeConversionSpec extends UnitSpec {\n\n  "Simple Spark DataType" should "be converted into SqlType" in {\n    SqlTypeConversion[IntegerType].getType shouldBe SqlInt()\n  }\n\n  "StructField nullable" should "be converted into Nullable SqlType" in {\n    val sf = StructField("myInt", IntegerType, nullable = true)\n    sf.asSqlType shouldBe SqlInt(Nullable)\n    SqlInstanceConversion[StructField].getType(sf) shouldBe SqlInt(Nullable)\n  }\n // ...\n}\n'})}),"\n",(0,t.jsx)(n.h2,{id:"conversion-type-class---sqltype-to-new-type",children:"Conversion: Type Class - SqlType to New Type"}),"\n",(0,t.jsx)(n.h3,{id:"defining-the-syntax",children:"Defining the syntax"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:["First, create a new package called something like ",(0,t.jsx)(n.code,{children:"org.datatools.bigdatatypes.{mynewtype}"})]}),"\n",(0,t.jsxs)(n.li,{children:["Add the Type Class (trait) with a method ",(0,t.jsx)(n.code,{children:"() => A"})," being ",(0,t.jsx)(n.code,{children:"A"})," our new type/schema\nFor example:"]}),"\n"]}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-scala",children:"trait SqlTypeToSpark[A] {\n\n  /** @return a list of [[StructField]]s that represents [[A]]\n    */\n  def sparkFields: List[StructField]\n}\n"})}),"\n",(0,t.jsxs)(n.p,{children:["In this case, ",(0,t.jsx)(n.code,{children:"sparkFields"})," will be the name of the method that we will use to obtain our new type.\nPick a representative name but don't worry too much, at the end we can create a wrapper class that we'll use our ",(0,t.jsx)(n.em,{children:"Type Class"}),"."]}),"\n",(0,t.jsx)(n.h3,{id:"implementing-the-type-class",children:"Implementing the Type Class"}),"\n",(0,t.jsxs)(n.p,{children:["We can start by creating a companion object with ",(0,t.jsx)(n.code,{children:"apply"})," and a factory constructor that will make easier construction of instances"]}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-scala",children:"object SqlTypeToSpark {\n\n  /** Summoner method */\n  def apply[A](implicit instance: SqlTypeToSpark[A]): SqlTypeToSpark[A] = instance\n\n  /** Factory constructor - allows easier construction of instances */\n  def instance[A](fs: List[StructField]): SqlTypeToSpark[A] =\n    new SqlTypeToSpark[A] {\n      def sparkFields: List[StructField] = fs\n    }\n}\n"})}),"\n",(0,t.jsxs)(n.p,{children:["Then, the code will depend a lot on the type that we are constructing, but we have to think that we are converting ",(0,t.jsx)(n.code,{children:"SqlType"}),"s into our type so,\nwe should do a method with like ",(0,t.jsx)(n.code,{children:"SqlType => ourType"})]}),"\n",(0,t.jsx)(n.p,{children:"As the types usually can be recursive (nested objects) we can start defining a method for the recursion that:"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsx)(n.li,{children:"Will take an SqlType"}),"\n",(0,t.jsxs)(n.li,{children:["Will use implicit ",(0,t.jsx)(n.code,{children:"Formats"})," as an optional key transformation"]}),"\n",(0,t.jsx)(n.li,{children:"Will return our desired type"}),"\n"]}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-scala",children:"  /** Creates the schema (list of fields)\n    * Applies an implicit [[Formats.transformKey]] in the process\n    * @param sqlType [[SqlType]]\n    * @param f [[Formats]] to apply while constructing the schema\n    * @return List of [[StructField]] representing the schema of the given type\n    */\n  private def getSchema(sqlType: SqlType)(implicit f: Formats): List[StructField] = sqlType match {\n    case SqlStruct(Nil, _) => Nil\n    case SqlStruct((name, sqlType) :: records, mode) =>\n      getSchemaWithName(f.transformKey(name, sqlType), sqlType) :: getSchema(SqlStruct(records, mode))\n  }\n"})}),"\n",(0,t.jsx)(n.admonition,{type:"tip",children:(0,t.jsxs)(n.p,{children:["This method probably could be copied, changing only the return type for our type. You will create ",(0,t.jsx)(n.code,{children:"getSchemaWithName"})," right now"]})}),"\n",(0,t.jsxs)(n.p,{children:["And another method (",(0,t.jsx)(n.code,{children:"getSchemaWithName"})," in this example) to specify the specific types:\nIn this case, we are showing an example from BigQuery as it seems simpler to understand:"]}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-scala",children:"/** Basic SqlTypes conversions to BigQuery Fields\n    */\n  private def getSchemaWithName(name: String, sqlType: SqlType)(implicit f: Formats): Field = sqlType match {\n    case SqlInt(mode) =>\n      Field.newBuilder(name, StandardSQLTypeName.INT64).setMode(sqlModeToBigQueryMode(mode)).build()\n    case SqlLong(mode) =>\n      Field.newBuilder(name, StandardSQLTypeName.INT64).setMode(sqlModeToBigQueryMode(mode)).build()\n    case SqlFloat(mode) =>\n      Field.newBuilder(name, StandardSQLTypeName.FLOAT64).setMode(sqlModeToBigQueryMode(mode)).build()\n    case SqlDouble(mode) => ???\n    case SqlDecimal(mode) => ???\n    case SqlBool(mode) => ???\n    case SqlString(mode) => ???\n    case SqlTimestamp(mode) => ???\n    case SqlDate(mode) => ???\n    case SqlStruct(subType, mode) => ???\n}\n"})}),"\n",(0,t.jsx)(n.p,{children:"Same example from Spark:"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-scala",children:"  /** Basic SqlTypes conversions to Spark Types\n    */\n  private def getSchemaWithName(name: String, sqlType: SqlType)(implicit f: Formats): StructField = sqlType match {\n    case SqlInt(mode) =>\n      StructField(name, sparkType(mode, IntegerType), isNullable(mode))\n    case SqlLong(mode) =>\n      StructField(name, sparkType(mode, LongType), isNullable(mode))\n    case SqlFloat(mode) =>\n      StructField(name, sparkType(mode, FloatType), isNullable(mode))\n  ...\n  ...\n  }\n"})}),"\n",(0,t.jsxs)(n.p,{children:["We have to understand ",(0,t.jsx)(n.code,{children:"Mode"})," at this point."]}),"\n",(0,t.jsx)(n.h4,{id:"mode-inside-types",children:"Mode inside Types"}),"\n",(0,t.jsx)(n.p,{children:"There are different ways to handle Arrays or repeated values in a structure and two are the most common."}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:["Define a Mode that can be ",(0,t.jsx)(n.code,{children:"Nullable"}),", ",(0,t.jsx)(n.code,{children:"Required"})," or ",(0,t.jsx)(n.code,{children:"Repeated"})," (this how ",(0,t.jsx)(n.code,{children:"SqlType"})," works).\n-- An Array will look like a normal type with ",(0,t.jsx)(n.code,{children:"Repeated"})," mode -> e.g: ",(0,t.jsx)(n.code,{children:"SqlInt(mode = Repeated)"})]}),"\n",(0,t.jsxs)(n.li,{children:["Define an ",(0,t.jsx)(n.code,{children:"Array"})," structure that has another type inside\n-- An Array will look like ",(0,t.jsx)(n.code,{children:"Array(Int)"})," or similar -> e.g: Spark -> ",(0,t.jsx)(n.code,{children:"ArrayType(IntegerType)"})]}),"\n"]}),"\n",(0,t.jsxs)(n.p,{children:["So, in BigQuery example, we use ",(0,t.jsx)(n.code,{children:"sqlModeToBigQueryMode"})," method as following:"]}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-scala",children:"  private def sqlModeToBigQueryMode(sqlTypeMode: SqlTypeMode): Mode = sqlTypeMode match {\n    case Nullable => Mode.NULLABLE\n    case Repeated => Mode.REPEATED\n    case Required => Mode.REQUIRED\n  }\n"})}),"\n",(0,t.jsx)(n.p,{children:"Pretty straight forward."}),"\n",(0,t.jsx)(n.p,{children:"In case of structs with Arrays like Spark, we use something like:"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-scala",children:"  private def sparkType(mode: SqlTypeMode, sparkType: DataType): DataType = mode match {\n    case Repeated => ArrayType(sparkType, containsNull = isNullable(mode))\n    case _        => sparkType\n  }\n"})}),"\n",(0,t.jsx)(n.p,{children:"Where if the mode is not repeated, we return the value, if it's repeated, we create an array with the value."}),"\n",(0,t.jsx)(n.h3,{id:"everything-together",children:"Everything together"}),"\n",(0,t.jsxs)(n.p,{children:["Finally, we create a method that derives the instance from ",(0,t.jsx)(n.code,{children:"SqlType"})," into our type, using our new methods. As simple as:"]}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-scala",children:"  /** Instance derivation via SqlTypeConversion.\n    */\n  implicit def fieldsFromSqlTypeConversion[A: SqlTypeConversion](implicit f: Formats): SqlTypeToSpark[A] =\n    instance(getSchema(SqlTypeConversion[A].getType))\n"})}),"\n",(0,t.jsx)(n.p,{children:"In order to understand it,"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.code,{children:"SqlTypeConversion[A].getType"})," will return the ",(0,t.jsx)(n.code,{children:"SqlType"})," for any type that implements ",(0,t.jsx)(n.code,{children:"SqlTypeConversion"}),",\nso we don't need to care about other types."]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.code,{children:"getSchema"})," is our new method that generates the complete type"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.code,{children:"instance"})," is our factory constructor that makes easier to construct the type class implementation"]}),"\n"]}),"\n",(0,t.jsxs)(n.p,{children:["And, that's it! Now ",(0,t.jsx)(n.strong,{children:"we can convert any Case Class into our new type"}),"!"]}),"\n",(0,t.jsx)(n.p,{children:"To do it, e.g:"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-scala",children:"SqlTypeToOurType[MyCaseClass].getMyNewType\n"})}),"\n",(0,t.jsxs)(n.p,{children:["Again, if you wonder how this happens, it's because ",(0,t.jsx)(n.a,{href:"https://github.com/data-tools/big-data-types/blob/main/core/src/main/scala/org/datatools/bigdatatypes/conversions/SqlTypeConversion.scala",children:"SqlTypeConversion"}),"\nType Class derives any Case Class into ",(0,t.jsx)(n.code,{children:"SqlType"})," using ",(0,t.jsx)(n.a,{href:"https://github.com/milessabin/shapeless",children:"Shapeless"})]}),"\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.strong,{children:"But"}),", one piece is still missing. Converting types is really cool, and it happens on compiler time,\nbut we also want to convert other types that live only in the running phase, like when we have an instance.\ne.g: An Spark Schema is not just a type, it's an instance of StructType, so we need to pass an instance to our new converter"]}),"\n",(0,t.jsx)(n.h2,{id:"conversion-sqlinstance-to-new-type",children:"Conversion: SqlInstance to New Type"}),"\n",(0,t.jsxs)(n.p,{children:["This will be quick as we already have methods that convert an ",(0,t.jsx)(n.code,{children:"SqlType"})," into our new type, so we only need to extend them to accept an instance as argument"]}),"\n",(0,t.jsxs)(n.p,{children:["We should create a new Type Class called ",(0,t.jsx)(n.code,{children:"SqlInstanceToOurType"})]}),"\n",(0,t.jsx)(n.p,{children:"As before, we create the syntax (for making it easier, we should have the same method name as before)"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-scala",children:"/** Type class to convert generic SqlTypes received as instance into BigQuery specific fields\n  * This uses [[SqlTypeToBigQuery]] to create BigQuery Fields\n  *\n  * @tparam A the type we want to obtain an schema from\n  */\ntrait SqlInstanceToBigQuery[A] {\n\n  /** @param value an instance of [[A]]\n    * @return a list of [[Field]]s that represents [[A]]\n    */\n  def bigQueryFields(value: A): List[Field]\n}\n"})}),"\n",(0,t.jsxs)(n.p,{children:["In this case, ",(0,t.jsx)(n.code,{children:"bigQueryFields"})," expects an input parameter A"]}),"\n",(0,t.jsx)(n.p,{children:"Next, we create the companion object with a few methods, starting by the summoner (apply)"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-scala",children:"object SqlInstanceToBigQuery {\n\n  /** Summoner method\n    */\n  def apply[A](implicit a: SqlInstanceToBigQuery[A]): SqlInstanceToBigQuery[A] = a\n"})}),"\n",(0,t.jsxs)(n.p,{children:["then, we add a method that will derive an instance of ",(0,t.jsx)(n.code,{children:"SqlInstance"})," into our new type"]}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-scala",children:"  /** Instance derivation via SqlTypeConversion. It uses `getSchema` from BigQueryTypes Type Class\n    */\n  implicit def fieldsFromSqlInstanceConversion[A: SqlInstanceConversion](implicit f: Formats): SqlInstanceToBigQuery[A] =\n    new SqlInstanceToBigQuery[A] {\n\n      override def bigQueryFields(value: A): List[Field] =\n        SqlTypeToBigQuery.getSchema(SqlInstanceConversion[A].getType(value))\n    }\n"})}),"\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.strong,{children:"Note!"}),": This is the full code of the implementation but in Scala we can reduce a lot the syntax. As there is only one method inside our Type Class,\nScala can understand that and there is no need to write all the code, so it can be written as follows:"]}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-scala",children:"  implicit def fieldsFromSqlInstanceConversion[A: SqlInstanceConversion](implicit f: Formats): SqlInstanceToBigQuery[A] =\n    (value: A) => SqlTypeToBigQuery.getSchema(SqlInstanceConversion[A].getType(value))\n"})}),"\n",(0,t.jsx)(n.p,{children:"both codes are equivalent!"}),"\n",(0,t.jsxs)(n.p,{children:["Another (optional) method more, to be able to use instances of ",(0,t.jsx)(n.code,{children:"SqlType"})," directly:"]}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-scala",children:"  implicit def fieldsFromSqlType(implicit f: Formats): SqlInstanceToBigQuery[SqlType] =\n    (value: SqlType) => SqlTypeToBigQuery.getSchema(value)\n"})}),"\n",(0,t.jsx)(n.p,{children:"And that's it! We can convert an instance of any type in the library into our new type, e.g: An Spark schema into our new type by doing:"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-scala",children:"SqlInstanceToOurType[StructType](mySparkSchema).getMyNewType\n"})}),"\n",(0,t.jsxs)(n.p,{children:["Finally, an extension method could help to improve the syntax. (Note: Scala 3 is improving the syntax for ",(0,t.jsx)(n.a,{href:"http://dotty.epfl.ch/docs/reference/contextual/extension-methods.html",children:"extension methods"}),")"]}),"\n",(0,t.jsx)(n.p,{children:"Inside the same object, we create an implicit class with our new syntax:"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-scala",children:"  /** Allows the syntax myInstance.asBigQuery for any instance of type A: SqlInstanceConversion\n    */\n  implicit class InstanceSyntax[A: SqlInstanceToBigQuery](value: A) {\n    def asBigQuery: List[Field] = SqlInstanceToBigQuery[A].bigQueryFields(value)\n  }\n"})}),"\n",(0,t.jsx)(n.p,{children:"And, we will win a new syntax like:"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-scala",children:"anyInstance.myNewType\nmySparkSchema.myNewType\n"})}),"\n",(0,t.jsx)(n.h2,{id:"reverse-conversion-new-type-to-sqltype",children:"Reverse conversion: New Type to SqlType"}),"\n",(0,t.jsx)(n.p,{children:"In this case we don't have to create a new Type Class, we have to implement the existing one with our concrete specification."}),"\n",(0,t.jsxs)(n.p,{children:["Implement ",(0,t.jsx)(n.a,{href:"https://github.com/data-tools/big-data-types/blob/main/core/src/main/scala/org/datatools/bigdatatypes/conversions/SqlTypeConversion.scala",children:"SqlTypeConversion"})," type class to have conversion from the new type to ",(0,t.jsx)(n.code,{children:"SqlType"}),"\nIt looks like this:"]}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-scala",children:"trait SqlTypeConversion[-A] {\n\n  def getType: SqlType\n}\n"})}),"\n",(0,t.jsx)(n.p,{children:"We can get an example of implementations from the same file, where Scala Types are being converted into SqlTypes like this:"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-scala",children:"implicit val intType: SqlTypeConversion[Int] = instance(SqlInt())\nimplicit val longType: SqlTypeConversion[Long] = instance(SqlLong())\nimplicit val doubleType: SqlTypeConversion[Double] = instance(SqlDouble())\n"})}),"\n",(0,t.jsxs)(n.p,{children:["As we did before, ",(0,t.jsx)(n.code,{children:"SqlTypeConversion"})," already have a factory constructor called ",(0,t.jsx)(n.code,{children:"instance()"})," that will make constructions of SqlTypes easier"]}),"\n",(0,t.jsx)(n.p,{children:"So, let's go to our code."}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:["First, create a new object called ",(0,t.jsx)(n.code,{children:"MyNewTypeConversion"}),", and add the basic type conversions (we don't care about names at this moment), like the one from Spark:"]}),"\n"]}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-scala",children:"object SparkTypeConversion {\n\n  /** SqlTypeConversion type class specifications for simple types\n    */\n  implicit val intType: SqlTypeConversion[IntegerType] = SqlTypeConversion.instance(SqlInt())\n  implicit val longType: SqlTypeConversion[LongType] = SqlTypeConversion.instance(SqlLong())\n  implicit val doubleType: SqlTypeConversion[DoubleType] = SqlTypeConversion.instance(SqlDouble())\n"})}),"\n",(0,t.jsx)(n.admonition,{type:"tip",children:(0,t.jsxs)(n.p,{children:["You can copy&paste all the available types from others modules like the ",(0,t.jsx)(n.a,{target:"_blank",href:s(8739).A+"",children:"Spark one"})]})}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:["Probably we use an instance of our type, for example, in Spark, we have ",(0,t.jsx)(n.code,{children:"StructField"})," and ",(0,t.jsx)(n.code,{children:"StructType"})," as instances, so we cover them using ",(0,t.jsx)(n.code,{children:"SqlInstanceConversion"})," ",(0,t.jsx)(n.em,{children:"Type Class"}),". In Cassandra we use internally a tuple ",(0,t.jsx)(n.code,{children:"(String, DataType)"}),", and it also works"]}),"\n"]}),"\n",(0,t.jsx)(n.p,{children:"We create an implementation of the type class for that type, for example in Cassandra:"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-scala",children:"  implicit val cassandraTupleType: SqlInstanceConversion[(String, DataType)] =\n    new SqlInstanceConversion[(String, DataType)] {\n      override def getType(value: (String, DataType)): SqlType = ???\n    }\n"})}),"\n",(0,t.jsxs)(n.p,{children:["We have to return a ",(0,t.jsx)(n.code,{children:"SqlType"})," that in the majority of the cases, it will be a ",(0,t.jsx)(n.code,{children:"StructType"})," with all fields inside.\nTo do so, will need a recursive function that creates it."]}),"\n",(0,t.jsx)(n.admonition,{type:"tip",children:(0,t.jsx)(n.p,{children:"When implementing a type class like the ones that we have here, with only one method,\nwe can use a reduced syntax that only needs the definition of the method. See below"})}),"\n",(0,t.jsxs)(n.p,{children:["This is the example from Spark, one for ",(0,t.jsx)(n.code,{children:"StructField"})," and another for ",(0,t.jsx)(n.code,{children:"StructType"}),", both using the ",(0,t.jsx)(n.em,{children:"reduced"})," syntax"]}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-scala",children:"  implicit val structField: SqlInstanceConversion[StructField] =\n    (value: StructField) => convertSparkType(value.dataType, value.nullable)\n\n  implicit val structType: SqlInstanceConversion[StructType] =\n    (value: StructType) => SqlStruct(loopStructType(value))\n"})}),"\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.code,{children:"convertSparkType"})," and ",(0,t.jsx)(n.code,{children:"loopSructType"})," are just methods that generate our types, see the example below:"]}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-scala",children:"  /** Given a Spark DataType, converts it into a SqlType\n    */\n  @tailrec\n  private def convertSparkType(dataType: DataType,\n                               nullable: Boolean,\n                               inheritMode: Option[SqlTypeMode] = None\n  ): SqlType = dataType match {\n    case IntegerType             => SqlInt(inheritMode.getOrElse(isNullable(nullable)))\n    case LongType                => SqlLong(inheritMode.getOrElse(isNullable(nullable)))\n    case DoubleType              => SqlDouble(inheritMode.getOrElse(isNullable(nullable)))\n    case FloatType               => SqlFloat(inheritMode.getOrElse(isNullable(nullable)))\n    case DecimalType()           => SqlDecimal(inheritMode.getOrElse(isNullable(nullable)))\n    case BooleanType             => SqlBool(inheritMode.getOrElse(isNullable(nullable)))\n    case StringType              => SqlString(inheritMode.getOrElse(isNullable(nullable)))\n    case TimestampType           => SqlTimestamp(inheritMode.getOrElse(isNullable(nullable)))\n    case DateType                => SqlDate(inheritMode.getOrElse(isNullable(nullable)))\n    case ArrayType(basicType, _) => convertSparkType(basicType, nullable, Some(Repeated))\n    case StructType(fields) =>\n      SqlStruct(loopStructType(StructType(fields)), inheritMode.getOrElse(isNullable(nullable)))\n  }\n"})}),"\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.code,{children:"inheritMode"})," can be confusing, but it is only to make the method tailrec"]}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:["One last (optional) step. If we want to make the usage easier, we can create an ",(0,t.jsx)(n.em,{children:"extension method"})]}),"\n"]}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-scala",children:"  /** Extension method. Enables val myInstance: StructType -> myInstance.asSqlType syntax and DataFrame.schema.asSqlType syntax\n    * @param value in a StructType (Spark Schema)\n    */\n  implicit class StructTypeSyntax(value: StructType) {\n    def asSqlType: SqlType = SqlInstanceConversion[StructType].getType(value)\n  }\n"})}),"\n",(0,t.jsx)(n.p,{children:"This method will allow any instance of the library to obtain our new type"}),"\n",(0,t.jsxs)(n.p,{children:["And, that's it! We have a way to convert our new type into ",(0,t.jsx)(n.code,{children:"SqlType"}),", but what does mean?\nIt means that ",(0,t.jsx)(n.em,{children:(0,t.jsx)(n.strong,{children:"we can import any other type from the library and convert our new type into any of the others."})})]}),"\n",(0,t.jsx)(n.h2,{id:"everything-together-1",children:"Everything together"}),"\n",(0,t.jsx)(n.p,{children:"Recap:"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:["We have 2 new type classes that converts ",(0,t.jsx)(n.code,{children:"SqlType"})," into our new type","\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:["The syntax can be confusing, but remember that probably no one will use an explicit conversion from ",(0,t.jsx)(n.code,{children:"SqlType"})," into our new Type."]}),"\n"]}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["We have the specification of ",(0,t.jsx)(n.code,{children:"SqlTypeConversion"})," and ",(0,t.jsx)(n.code,{children:"SqlInstanceConversion"})," that converts our new type into ",(0,t.jsx)(n.code,{children:"SqlType"})]}),"\n"]}),"\n",(0,t.jsxs)(n.p,{children:["For the latter, we could create a ",(0,t.jsx)(n.em,{children:"Wrapper"})," that will add some custom features or improve the syntax."]}),"\n",(0,t.jsxs)(n.p,{children:["In the case of Spark, we have an object that allows us to do a simple thing like ",(0,t.jsx)(n.code,{children:"SparkSchemas.schema[MyCaseClass]"})," and also gives us the ability to concatenate case classes"]}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-scala",children:"object SparkSchemas {\n def schema[A: SqlTypeToSpark]: StructType = SqlTypeToSpark[A].sparkSchema\n def schema[A: SqlTypeToSpark, B: SqlTypeToSpark]: StructType = StructType(fields[A, B])\n\n def fields[A: SqlTypeToSpark]: List[StructField] = SqlTypeToSpark[A].sparkFields\n def fields[A: SqlTypeToSpark, B: SqlTypeToSpark]: List[StructField] = SqlTypeToSpark[A].sparkFields ++ SqlTypeToSpark[B].sparkFields\n}\n"})}),"\n",(0,t.jsx)(n.p,{children:"That's all!"}),"\n",(0,t.jsx)(n.p,{children:"Feel free to contribute, open issues, discussions or give feedback"})]})}function h(e={}){const{wrapper:n}={...(0,l.R)(),...e.components};return n?(0,t.jsx)(n,{...e,children:(0,t.jsx)(d,{...e})}):d(e)}},805:(e,n,s)=>{s.d(n,{A:()=>t});const t=s.p+"assets/files/TestTypes-3c8ab25ed899efb68a9053689b1e8203.scala"},8739:(e,n,s)=>{s.d(n,{A:()=>t});const t=s.p+"assets/files/SparkTypeConversion-87709912ee87b4fc39da2956723af6d5.scala"},8453:(e,n,s)=>{s.d(n,{R:()=>r,x:()=>a});var t=s(6540);const l={},i=t.createContext(l);function r(e){const n=t.useContext(i);return t.useMemo((function(){return"function"==typeof e?e(n):{...n,...e}}),[n,e])}function a(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(l):e.components||l:r(e.components),t.createElement(i.Provider,{value:n},e.children)}}}]);